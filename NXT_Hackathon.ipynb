{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouP7ANZRF04L",
        "outputId": "ddf185ef-c01e-4b15-a61e-526e4fbfbca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# Update the path to your dataset file in Google Drive\n",
        "data_link = '/content/drive/MyDrive/NXT Hackathon Data /Watches Data Dump.csv'\n",
        "data = pd.read_csv(data_link)"
      ],
      "metadata": {
        "id": "GEJvUzRf-a8x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkV1mbND-zkJ",
        "outputId": "a0f73831-ef59-4892-f057-530039dcf802"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import silhouette_score\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the folder containing all CSV files\n",
        "data_folder = \"/content/drive/MyDrive/NXT_Hackathon_Data/\"\n",
        "output_folder = \"/content/drive/MyDrive/NXT_Hackathon_Output/\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# List of all CSV files\n",
        "data_files = [\n",
        "    \"Bathroom Vanities Data Dump.csv\",\n",
        "    \"Data Dump Kurtis.csv\",\n",
        "    \"Dresses Data Dump.csv\",\n",
        "    \"Earrings Data Dump.csv\",\n",
        "    \"Jeans Data Dump.csv\",\n",
        "    \"Saree Data_dump.csv\",\n",
        "    \"shirts_data_dump.csv\",\n",
        "    \"Sneakers Data Dump.csv\",\n",
        "    \"Tshirts Data Dump.csv\",\n",
        "    \"Watches Data Dump.csv\"\n",
        "]\n",
        "\n",
        "# Device setup for GPU/CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --------------------------\n",
        "# STEP 1: Load Pre-trained Models\n",
        "# --------------------------\n",
        "print(\"Loading pre-trained models...\")\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "bert_model.eval()\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "resnet_model = models.resnet50(pretrained=True).to(device)\n",
        "resnet_model.eval()\n",
        "resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1]))\n",
        "\n",
        "# Image preprocessing transformations\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --------------------------\n",
        "# STEP 2: Helper Functions\n",
        "# --------------------------\n",
        "def get_bert_embedding(text):\n",
        "    \"\"\"Generate BERT embeddings for a given text.\"\"\"\n",
        "    inputs = bert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()\n",
        "    return cls_embedding\n",
        "\n",
        "def get_image_embedding(image_url):\n",
        "    \"\"\"Generate ResNet embeddings for a given image.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(image_url, timeout=5)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        image = image_transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            embedding = resnet_model(image).squeeze().cpu().numpy()\n",
        "        return embedding.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_url}: {e}\")\n",
        "        return np.zeros(2048)\n",
        "\n",
        "def find_optimal_clusters(features, max_clusters=10):\n",
        "    \"\"\"Determine the optimal number of clusters using the Silhouette Score.\"\"\"\n",
        "    best_score = -1\n",
        "    best_num_clusters = 2  # Minimum clusters to test\n",
        "    for n_clusters in range(2, max_clusters + 1):\n",
        "        clustering_model = AgglomerativeClustering(n_clusters=n_clusters, affinity='cosine', linkage='average')\n",
        "        cluster_labels = clustering_model.fit_predict(features)\n",
        "        score = silhouette_score(features, cluster_labels, metric='cosine')\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_num_clusters = n_clusters\n",
        "    return best_num_clusters\n",
        "\n",
        "# --------------------------\n",
        "# STEP 3: Process Each File\n",
        "# --------------------------\n",
        "all_data = []  # To store combined data across all CSVs\n",
        "\n",
        "for file in data_files:\n",
        "    print(f\"Processing {file}...\")\n",
        "\n",
        "    # Load dataset\n",
        "    file_path = os.path.join(data_folder, file)\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Fill missing values\n",
        "    data['description'] = data['description'].fillna(\"\")\n",
        "    data['feature_image'] = data['feature_image'].fillna(\"\")\n",
        "\n",
        "    # Extract text features\n",
        "    print(\"Extracting textual features...\")\n",
        "    text_features = np.array([get_bert_embedding(desc) for desc in data['description']])\n",
        "    text_features = normalize(text_features)\n",
        "\n",
        "    # Extract image features\n",
        "    print(\"Extracting image features...\")\n",
        "    image_features = np.array([get_image_embedding(img_url) for img_url in data['feature_image']])\n",
        "    image_features = normalize(image_features)\n",
        "\n",
        "    # Combine text and image features\n",
        "    print(\"Combining features...\")\n",
        "    combined_features = np.hstack((text_features, image_features))\n",
        "\n",
        "    # Determine the optimal number of clusters\n",
        "    print(\"Determining the optimal number of clusters...\")\n",
        "    optimal_clusters = find_optimal_clusters(combined_features)\n",
        "    print(f\"Optimal number of clusters for {file}: {optimal_clusters}\")\n",
        "\n",
        "    # Perform clustering with the optimal number of clusters\n",
        "    print(\"Clustering features...\")\n",
        "    clustering_model = AgglomerativeClustering(n_clusters=optimal_clusters, affinity='cosine', linkage='average')\n",
        "    cluster_labels = clustering_model.fit_predict(combined_features)\n",
        "\n",
        "    # Add cluster labels to the dataset\n",
        "    data['cluster'] = cluster_labels\n",
        "\n",
        "    # Append to all_data\n",
        "    all_data.append(data)\n",
        "\n",
        "    # Create an ontology for the file\n",
        "    print(\"Creating ontology...\")\n",
        "    ontology = {}\n",
        "    for cluster_id in range(optimal_clusters):\n",
        "        cluster_data = data[data['cluster'] == cluster_id]\n",
        "        ontology[f\"Cluster {cluster_id}\"] = {\n",
        "            \"size\": len(cluster_data),\n",
        "            \"categories\": cluster_data['category_name'].unique().tolist() if 'category_name' in cluster_data else [],\n",
        "            \"brands\": cluster_data['brand'].unique().tolist() if 'brand' in cluster_data else [],\n",
        "            \"sample_products\": cluster_data['product_name'].tolist()[:10] if 'product_name' in cluster_data else []\n",
        "        }\n",
        "\n",
        "    # Save ontology as JSON\n",
        "    ontology_file = os.path.join(output_folder, f\"ontology_{file.split('.')[0]}.json\")\n",
        "    with open(ontology_file, \"w\") as json_file:\n",
        "        json.dump(ontology, json_file, indent=4)\n",
        "\n",
        "    print(f\"Ontology for {file} saved to: {ontology_file}\")\n",
        "\n",
        "# Combine all data and save to a single file\n",
        "final_data = pd.concat(all_data, ignore_index=True)\n",
        "final_output_file = os.path.join(output_folder, \"combined_clustered_data.csv\")\n",
        "final_data.to_csv(final_output_file, index=False)\n",
        "\n",
        "print(f\"Combined clustered data saved to: {final_output_file}\")\n"
      ],
      "metadata": {
        "id": "5V6VwrEdG_kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "144c4bfa-ef16-4cf1-9480-97e8dca8e8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cf2d6631de92>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2476\u001b[0m     \u001b[0mexport\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPassManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from torch.utils._pytree import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_drawer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnet_min_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparam_fetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/graph_drawer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_format_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_qualified_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator_schemas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_prop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/passes/shape_prop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcompatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_backward_compatible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mShapeProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m     76\u001b[0m     \u001b[0mExecute\u001b[0m \u001b[0man\u001b[0m \u001b[0mFX\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mNode\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MiVrJRSh-W3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}